train:
  tensorboard_path: ./logs/
  log_interval_steps: 10
  epochs: 300
  optimizer:
    lr: 1e-2
    weight_decay: 0.0
  seed: 42
  monitor: val_loss_fusion
  monitor_mode: min

dataset:
  type: MIMICDataModule
  params:
    data_dir: ../data/mimic
    task: -1
    batch_size: 128
    num_workers: 0

model:
  type: MimicRecurrent
  dropout: 0.1
#  fusion_loss_weight: 0.1
#  fusion_loss_change: 0.05
#  loss_change_epoch: 10
  gradblend: True
  modalities:
    classification:
      num_classes: 6
      classifier: StandardClassifier
      input_shape: [16, 1024, 40]
    time:
      block_type: GRU
      input_dim: 12
      hidden_dim: 30
      flatten: True
      batch_first: True
    static:
      block_type: MLP
      in_channels: 1
      input_dim: 5
      hidden_dim: 10
      num_blocks: 1
      output_dim: 10
    multimodal:
      block_type: MLP
      fusion_function: ConcatFusion
      input_dim: 730
      hidden_dim: 40
      num_blocks: 1
